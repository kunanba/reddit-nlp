{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>slftxt_ttl</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/malefashionadvice/com...</td>\n",
       "      <td># Welcome to /r/MaleFashionAdvice!\\n\\n*MaleFas...</td>\n",
       "      <td>Welcome to /r/MaleFashionAdvice! Please click ...</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td># Welcome to /r/MaleFashionAdvice!\\n\\n*MaleFas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/malefashionadvice/com...</td>\n",
       "      <td>Welcome to the Daily Questions thread! Our dai...</td>\n",
       "      <td>Daily Questions - ASK AND ANSWER HERE!- July 10</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>Welcome to the Daily Questions thread! Our dai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://imgur.com/a/OFYDiC1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Linen: Embrace the Wrinkles</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>Linen: Embrace the Wrinkles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.fastcompany.com/90371799/for-adida...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adidas by Stella McCartney is making new cloth...</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>Adidas by Stella McCartney is making new cloth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://medium.com/@apparelandattire2018/profi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apparel &amp;amp; Attire interview: Our very own /...</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>Apparel &amp;amp; Attire interview: Our very own /...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url  \\\n",
       "0           0  https://www.reddit.com/r/malefashionadvice/com...   \n",
       "1           1  https://www.reddit.com/r/malefashionadvice/com...   \n",
       "2           2                        https://imgur.com/a/OFYDiC1   \n",
       "3           3  https://www.fastcompany.com/90371799/for-adida...   \n",
       "4           4  https://medium.com/@apparelandattire2018/profi...   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  # Welcome to /r/MaleFashionAdvice!\\n\\n*MaleFas...   \n",
       "1  Welcome to the Daily Questions thread! Our dai...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               title          subreddit  \\\n",
       "0  Welcome to /r/MaleFashionAdvice! Please click ...  malefashionadvice   \n",
       "1    Daily Questions - ASK AND ANSWER HERE!- July 10  malefashionadvice   \n",
       "2                        Linen: Embrace the Wrinkles  malefashionadvice   \n",
       "3  Adidas by Stella McCartney is making new cloth...  malefashionadvice   \n",
       "4  Apparel &amp; Attire interview: Our very own /...  malefashionadvice   \n",
       "\n",
       "                                          slftxt_ttl  target  \n",
       "0  # Welcome to /r/MaleFashionAdvice!\\n\\n*MaleFas...       1  \n",
       "1  Welcome to the Daily Questions thread! Our dai...       1  \n",
       "2                        Linen: Embrace the Wrinkles       1  \n",
       "3  Adidas by Stella McCartney is making new cloth...       1  \n",
       "4  Apparel &amp; Attire interview: Our very own /...       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_data2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['target'] = df['subreddit'].map(lambda x: 1 if x=='malefashionadvice' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1960\n",
       "1    1875\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "\n",
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe for the model\n",
    "\n",
    "df1 = df[['slftxt_ttl', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initiated lemmatizer and stemmatizer in order to see how these preprocessing tools affect my model. It turns out that the models perform better withouth these preprocessing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msgs_to_words(msgs):\n",
    "\n",
    "    msgs_text = BeautifulSoup(msgs).get_text()\n",
    "    \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", msgs)\n",
    "\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "#     lem_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "    stem_words = [p_stemmer.stem(i) for i in words]\n",
    "    \n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    meaningful_words = [w for w in stem_words if not w in stops]\n",
    "\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into training and validating set in order to evaluate our model on the validating set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['slftxt_ttl'], df['target'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the NLP model the features have to be CountVectorized. The CountVectorizer transforms the features and in the case of this project creates the matrix containing all the words that the dataset contains and their respective number of counts in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(analyzer='word',\n",
    "                      max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cvec = cvec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use three classification models and score them in order to compare.\n",
    "\n",
    "- Logistic Regression provides better result compared to KNearest Neighbour and Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8856050069541029\n",
      "0.881126173096976\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_cvec, y_train)\n",
    "print(mnb.score(X_train_cvec, y_train))\n",
    "print(mnb.score(X_test_cvec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rauan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989568845618915\n",
      "0.9822732012513035\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_cvec, y_train)\n",
    "print(lr.score(X_train_cvec, y_train))\n",
    "print(lr.score(X_test_cvec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9012517385257302\n",
      "0.8633993743482794\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_cvec, y_train)\n",
    "print(knn.score(X_train_cvec, y_train))\n",
    "print(knn.score(X_test_cvec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mnb.predict(X_test_cvec)\n",
    "resids = y_test - preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[447,  89],\n",
       "       [ 25, 398]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created confusion matrix for both Naive Bayes and Logistic Regression in order to interpret the results. The tables below clearly showcase Logisic Regression outperforming Naive Bayes model with zero False Positives as opposed to 89 posts. Although the False Negatives did not differ as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred female</th>\n",
       "      <th>pred male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual female</th>\n",
       "      <td>447</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual male</th>\n",
       "      <td>25</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred female  pred male\n",
       "actual female          447         89\n",
       "actual male             25        398"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(preds, y_test),\n",
    "             columns=['pred female', 'pred male'], index=['actual female', 'actual male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       472\n",
      "           1       0.94      0.82      0.87       487\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       959\n",
      "   macro avg       0.89      0.88      0.88       959\n",
      "weighted avg       0.89      0.88      0.88       959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred female</th>\n",
       "      <th>pred male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual female</th>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual male</th>\n",
       "      <td>17</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred female  pred male\n",
       "actual female          455          0\n",
       "actual male             17        487"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(predictions, y_test),\n",
    "             columns=['pred female', 'pred male'], index=['actual female', 'actual male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       472\n",
      "           1       0.97      1.00      0.98       487\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       959\n",
      "   macro avg       0.98      0.98      0.98       959\n",
      "weighted avg       0.98      0.98      0.98       959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>200</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>wrong</th>\n",
       "      <th>www</th>\n",
       "      <th>x200b</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   03  05  09  10  100  11  12  15  20  200  ...  would  wrong  www  x200b  \\\n",
       "0   0   0   0   0    0   0   0   0   0    0  ...      0      0    0      0   \n",
       "1   0   0   0   0    0   0   0   0   0    0  ...      0      0    0      0   \n",
       "2   0   0   0   0    2   0   0   0   0    0  ...      2      0    0      0   \n",
       "3   0   0   0   0    0   0   0   0   0    1  ...      0      0    0      0   \n",
       "4   0   0   0   1    0   0   0   0   0    0  ...      1      0    0      0   \n",
       "5   0   0   0   0    0   0   0   0   0    0  ...      0      0    0      0   \n",
       "6   0   0   0   2    1   0   0   0   0    0  ...      1      0   70      0   \n",
       "7   0   0   0   0    0   0   0   0   0    0  ...      0      0    0      0   \n",
       "8   0   0   0   0    0   0   0   0   0    0  ...      0      3    1      0   \n",
       "9   0   0   0   0    0   0   0   0   0    0  ...      0      0    4      0   \n",
       "\n",
       "   year  years  yet  you  your  yourself  \n",
       "0     0      0    0    0     0         0  \n",
       "1     0      0    0    3     2         0  \n",
       "2     2      0    0    1     1         0  \n",
       "3     0      0    0    1     0         0  \n",
       "4     0      1    0    3     0         0  \n",
       "5     0      0    0    3     3         0  \n",
       "6     1      1    0    7     5         0  \n",
       "7     0      0    0    0     0         0  \n",
       "8     0      0    0   11     4         0  \n",
       "9     0      0    0    5     2         0  \n",
       "\n",
       "[10 rows x 1000 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_matrix = X_train_cvec.todense()\n",
    "feature_df = pd.DataFrame(dense_matrix, columns=cvec.get_feature_names())\n",
    "feature_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_df.sum().sort_values(ascending=False).head(15).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above it can be seen the the most common words in the threads are basically stop words, so I decided to bring in the Pipeline and GridSearch in order to see how models performed with the various lists of Stop words. I tweaked the parameters of the CountVectorizer, and used Pipeline to employ Naive Bayes model and the Logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('cvec', CountVectorizer()),\n",
    "                ('mnb', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9175938803894298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stop = list(ENGLISH_STOP_WORDS)\n",
    "# my_stop.extend(['edu', 'com'])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2000, 4000],\n",
    "    'cvec__min_df': [3, 50],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'cvec__stop_words': ['english', my_stop]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516689847009736"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374348279457768"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predics = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred female</th>\n",
       "      <th>pred male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual female</th>\n",
       "      <td>468</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual male</th>\n",
       "      <td>4</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred female  pred male\n",
       "actual female          468         56\n",
       "actual male              4        431"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(predics, y_test),\n",
    "            columns=['pred female', 'pred male'], index=['actual female', 'actual male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       472\n",
      "           1       0.97      1.00      0.98       487\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       959\n",
      "   macro avg       0.98      0.98      0.98       959\n",
      "weighted avg       0.98      0.98      0.98       959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([('cvec', CountVectorizer()),\n",
    "                ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Rauan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787899860917941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 30,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stop = list(ENGLISH_STOP_WORDS)\n",
    "\n",
    "params = {\n",
    "    'cvec__max_features': [2000, 4000],\n",
    "    'cvec__min_df': [3, 30],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'cvec__stop_words': ['english', None, my_stop]\n",
    "}\n",
    "gs2 = GridSearchCV(pipe2, param_grid=params, cv=3, verbose=1)\n",
    "gs2.fit(X_train, y_train)\n",
    "print(gs2.best_score_)\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916579770594369"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gs2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred female</th>\n",
       "      <th>pred male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual female</th>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual male</th>\n",
       "      <td>8</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred female  pred male\n",
       "actual female          464          0\n",
       "actual male              8        487"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(pred, y_test),\n",
    "            columns=['pred female', 'pred male'], index=['actual female', 'actual male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       472\n",
      "           1       0.98      1.00      0.99       487\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       959\n",
      "   macro avg       0.99      0.99      0.99       959\n",
      "weighted avg       0.99      0.99      0.99       959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed above that the Logist Regression outperforms the Naiev Bayes and also requires less features for the model, in essence requiring less time to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check out the project and the EDA click on this [link](./Project_3.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
